# app/services/geoai_pipeline.py

from app.services.geoai_feature_engineer import GeoAIFeatureEngineer
from app.services.geoai_model import GeoAIClassifier

import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.metrics import (
    precision_score,
    recall_score,
    f1_score,
    confusion_matrix,
)


plt.rcParams["font.family"] = "Malgun Gothic"
plt.rcParams["axes.unicode_minus"] = False


class GeoAIPipeline:
    def __init__(self):
        self.engineer = GeoAIFeatureEngineer()
        self.model = GeoAIClassifier()

    # --------------------- Train (ë‚´ë¶€ test í¬í•¨) ---------------------
    def run(self):
        """
        1) train.csv ì— ëŒ€í•´ Feature Engineering ì‹¤í–‰
        2) RandomForest í•™ìŠµ + (train ë‚´ë¶€) test ì„±ëŠ¥ ì¶œë ¥
        """
        print("ğŸš€ GeoAI FeatureEngineer (ì¶•ì†Œë²„ì „) í™œì„±í™”\n")
        df_train = self.engineer.run()   # ì—¬ê¸°ì„œ train.csv + ê³µê°„ í”¼ì²˜ ë¶™ìŒ
        df_train = df_train.loc[:, ~df_train.columns.duplicated()]  # ì¶”ê°€
        clf = self.model.train(df_train) # ì—¬ê¸°ì„œ train/test split + ì„±ëŠ¥ ì¶œë ¥
        self.model.clf = clf

        return df_train

    # ---------------- Feature Importance PNG ì €ì¥ ----------------
    def save_feature_importance(self, output_path="feature_importance.png"):
        clf = self.model.clf
        feature_names = self.model.feature_names_

        importances = clf.feature_importances_
        indices = np.argsort(importances)

        plt.figure(figsize=(10, 8))
        plt.title("Feature Importance (Random Forest)", fontsize=16)
        plt.barh(range(len(indices)), importances[indices])
        plt.yticks(
            range(len(indices)),
            [feature_names[i] for i in indices],
            fontsize=9,
        )
        plt.xlabel("Importance", fontsize=12)
        plt.tight_layout()
        plt.savefig(output_path, dpi=300)
        plt.close()

        print(f"ğŸ“Œ Feature Importance ì €ì¥ë¨ â†’ {output_path}")

    # ---------------- Confusion Matrix PNG ì €ì¥ ----------------
    def save_confusion_matrix(self, output_path="confusion_matrix.png"):
        y_true = self.model.last_y_test
        y_pred = self.model.last_y_pred

        if y_true is None or y_pred is None:
            print("âš ï¸ ì•„ì§ train ë‚´ë¶€ test ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        labels = sorted(list(set(y_true)))
        cm = confusion_matrix(y_true, y_pred, labels=labels)

        plt.figure(figsize=(10, 8))
        sns.heatmap(
            cm,
            annot=True,
            fmt="d",
            cmap="Blues",
            xticklabels=labels,
            yticklabels=labels,
        )
        plt.title("Confusion Matrix (Internal Test Split)", fontsize=16)
        plt.ylabel("True Label")
        plt.xlabel("Predicted Label")
        plt.tight_layout()
        plt.savefig(output_path, dpi=300)
        plt.close()

        print(f"ğŸ“Œ Confusion Matrix ì €ì¥ë¨ â†’ {output_path}")

    # ---------------- Classë³„ ì„±ëŠ¥ í‘œ ì¶œë ¥ ----------------
    def print_class_performance(self):
        y_true = self.model.last_y_test
        y_pred = self.model.last_y_pred

        if y_true is None or y_pred is None:
            print("âš ï¸ ì•„ì§ train ë‚´ë¶€ test ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        labels = sorted(list(set(y_true)))

        print("\nğŸ“Š === Classë³„ ì„±ëŠ¥ ìš”ì•½ (Internal Test Split ê¸°ì¤€) ===")
        print(f"{'í´ë˜ìŠ¤':<12} {'Precision':>10} {'Recall':>10} {'F1':>10}")

        for cls in labels:
            p = precision_score(
                y_true, y_pred, labels=[cls], average="macro", zero_division=0
            )
            r = recall_score(
                y_true, y_pred, labels=[cls], average="macro", zero_division=0
            )
            f = f1_score(
                y_true, y_pred, labels=[cls], average="macro", zero_division=0
            )
            print(f"{cls:<12} {p:>10.2f} {r:>10.2f} {f:>10.2f}")


    @staticmethod
    def align_test_columns(df_test, train_features):
        # 1) ê³µë°± ì œê±°
        df_test.columns = df_test.columns.str.strip()

        # 2) trainì— ìˆëŠ”ë° testì— ì—†ëŠ” ì»¬ëŸ¼ì€ 0ìœ¼ë¡œ ìƒì„±
        for col in train_features:
            if col not in df_test.columns:
                df_test[col] = 0

        # 3) testì— ìˆëŠ”ë° trainì— ì—†ëŠ” ì»¬ëŸ¼ì€ ì‚­ì œ
        cols_to_drop = [
            c for c in df_test.columns
            if c not in train_features and c != "ëŒ€ë¶„ë¥˜"
        ]
        if cols_to_drop:
            df_test = df_test.drop(columns=cols_to_drop)

        # 4) ìˆœì„œ ê°•ì œ ì •ë ¬
        df_test = df_test[train_features]

        return df_test

    
    # ---------------- (ì˜µì…˜) test_data.csv ë³„ë„ í‰ê°€ ----------------
    def evaluate_on_test(self, test_csv_path: str):
        print(f"ğŸ“‚ test CSV ë¡œë“œ ì¤‘ â†’ {test_csv_path}")

        df_test_fe = self.engineer.run_test(test_csv_path)
        df_test_fe = df_test_fe.loc[:, ~df_test_fe.columns.duplicated()]
        print("ğŸ“Š test feature-engineered shape:", df_test_fe.shape)

        train_features = self.model.feature_names_
        print("ğŸ”¥ TRAIN FEATURE LIST:", train_features)

        # --- ì—¬ê¸°ì„œ test featureë¥¼ trainê³¼ ì™„ì „íˆ ë™ì¼í•˜ê²Œ ì¬êµ¬ì„± ---
        df_test_aligned = pd.DataFrame({
            col: df_test_fe[col].astype(float)
            for col in train_features
        })  

        print("ğŸ”¥ TEST ALIGNED COLS:", df_test_aligned.columns.tolist())

        preds = self.model.clf.predict(df_test_aligned)
        print("ğŸ¯ === TEST ì˜ˆì¸¡ ê²°ê³¼ ===")
        print(preds[:20])

        # test CSV ì— 'ëŒ€ë¶„ë¥˜' ìˆìœ¼ë©´ ì„±ëŠ¥ë„ ì¶œë ¥
        if "ëŒ€ë¶„ë¥˜" in df_test_fe.columns:
            y_true = df_test_fe["ëŒ€ë¶„ë¥˜"]
            print("\nğŸ“Š === TEST ì„±ëŠ¥ (test_data.csv ê¸°ì¤€) ===")
            from sklearn.metrics import classification_report
            print(classification_report(y_true, preds))

        return preds


if __name__ == "__main__":
    pipe = GeoAIPipeline()

    # 1) train.csv ê¸°ì¤€ìœ¼ë¡œ í•™ìŠµ + ë‚´ë¶€ test í‰ê°€
    pipe.run()

    # 2) ê·¸ ë‚´ë¶€ test ê²°ê³¼ ê¸°ì¤€ìœ¼ë¡œ PNG/í‘œ ë½‘ê¸°
    #   (ìƒì„± ê²½ë¡œ: app/services/feature_importance.png, confusion_matrix.png)
    pipe.save_feature_importance("feature_importance.png")
    pipe.save_confusion_matrix("confusion_matrix.png")
    pipe.print_class_performance()

    # 3) test_data.csv ë³„ë„ í‰ê°€ê°€ ì§„ì§œ í•„ìš”í•˜ë©´, ì´ ì¤„ì„ ìˆ˜ë™ìœ¼ë¡œ ì¶”ê°€í•´ì„œ ì‚¬ìš©
    pipe.evaluate_on_test(r"data/test_data.csv")
